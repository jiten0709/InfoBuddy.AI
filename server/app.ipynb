{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6773bc6a",
   "metadata": {},
   "source": [
    "# Comprehensive test suite for the InfoBuddy.AI Server\n",
    "\n",
    "This notebook provides a comprehensive implementation of a chat assistant using:\n",
    "- <xyz> llm for conversational AI\n",
    "- Tavily Search for real-time web information\n",
    "- LangGraph for workflow orchestration\n",
    "- Memory management for conversation continuity\n",
    "\n",
    "Features:\n",
    "- Class-based architecture with clear separation of concerns\n",
    "- Comprehensive error handling and logging\n",
    "- Type safety with complete annotations\n",
    "- Debugging and visualization capabilities\n",
    "- Industry best practices implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff7040",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4f44c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional, TypedDict, Any, Union, Annotated, Dict\n",
    "from langgraph.graph import add_messages, StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import json\n",
    "from uuid import uuid4\n",
    "\n",
    "import os\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\",\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler(filename='logs/app.log', mode='a')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715107c",
   "metadata": {},
   "source": [
    "## schema / state definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22663e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatConversationState(TypedDict):\n",
    "    \"\"\"\n",
    "    Enhanced state definition for chat conversation management.\n",
    "    \n",
    "    This TypedDict defines the structure of the conversation state that flows\n",
    "    through the LangGraph workflow, ensuring type safety and clear data contracts.\n",
    "    \n",
    "    Attributes:\n",
    "        messages: List of conversation messages with automatic message addition functionality\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91357b",
   "metadata": {},
   "source": [
    "## chat assistant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1deb3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatAssistantNotebook:\n",
    "    \"\"\"\n",
    "    Production-ready chat assistant implementation for Jupyter notebooks.\n",
    "    \n",
    "    This class encapsulates all chat assistant functionality including:\n",
    "    - LLM integration with <xyz> llm\n",
    "    - Web search capabilities via Tavily\n",
    "    - Conversation memory management\n",
    "    - Graph-based workflow orchestration\n",
    "    - Comprehensive error handling and logging\n",
    "    \n",
    "    Attributes:\n",
    "        model: <xyz> model instance\n",
    "        search_tool: Tavily search tool for web queries\n",
    "        memory_manager: Conversation memory checkpoint manager\n",
    "        conversation_graph: Compiled LangGraph workflow\n",
    "        \n",
    "    Example:\n",
    "        >>> assistant = ChatAssistantNotebook()\n",
    "        >>> await assistant.process_user_message(\"What's the weather today?\")\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str = 'gemini-2.5-flash',\n",
    "            max_search_results: int = 2,\n",
    "    ):\n",
    "        logger.info(\"üöÄ Initializing Enhanced Chat Assistant...\")\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.max_search_results = max_search_results\n",
    "        self.app = None\n",
    "        self.model = None\n",
    "        self.search_tool = None\n",
    "        self.memory = None\n",
    "        self.available_tools = []\n",
    "        self.llm = None\n",
    "        self.enhanced_llm = None\n",
    "\n",
    "        try:\n",
    "            \n",
    "            self._initialize_language_model()\n",
    "            self._initialize_search_capabilities()\n",
    "            self._initialize_memory_management()\n",
    "            self._setup_conversation_workflow()\n",
    "            logger.info(\"‚úÖ Chat Assistant initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Initialization failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _initialize_language_model(self) -> None:\n",
    "        \"\"\" Initialize the <xyz> language model\"\"\"\n",
    "        try:\n",
    "            self.llm = ChatGoogleGenerativeAI(model=self.model_name, temperature=0.1)\n",
    "            logger.info(f\"‚úÖ Language model '{self.model_name}' initialized.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to initialize language model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _initialize_search_capabilities(self) -> None:\n",
    "        \"\"\" Initialize the Tavily search tool \"\"\"\n",
    "        try:\n",
    "            self.search_tool = TavilySearchResults(max_results=self.max_search_results)\n",
    "            self.available_tools = [self.search_tool]\n",
    "\n",
    "            # bind tools to llm\n",
    "            self.enhanced_llm = self.llm.bind_tools(tools=self.available_tools)\n",
    "\n",
    "            logger.info(\"‚úÖ Search tool initialized and enhances llm capabilities.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to initialize search tool capabilities: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _initialize_memory_management(self) -> None:\n",
    "        \"\"\" Initialize the conversation memory manager\"\"\"\n",
    "        try: \n",
    "            self.memory = MemorySaver()\n",
    "            logger.info(\"‚úÖ Memory manager initialized.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to initialize memory manager: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _setup_conversation_workflow(self) -> None:\n",
    "        \"\"\" Setup the LangGraph conversation workflow\"\"\"\n",
    "        try:\n",
    "            # create the state graph\n",
    "            graph = StateGraph(ChatConversationState)\n",
    "\n",
    "            # add nodes\n",
    "            graph.add_node('llm_node', self._execute_language_model_processing)\n",
    "            graph.add_node('tool_execution_node', self._execute_tool_operations)\n",
    "\n",
    "            # set entry point\n",
    "            graph.set_entry_point('llm_node')\n",
    "\n",
    "            # add edges\n",
    "            graph.add_conditional_edges('llm_node', self._route_to_appropriate_node)\n",
    "            graph.add_edge('tool_execution_node', 'llm_node')\n",
    "\n",
    "            # compile the graph\n",
    "            self.app = graph.compile(checkpointer=self.memory)\n",
    "\n",
    "            logger.info(\"‚úÖ Conversation workflow graph created and compiled.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to create state graph: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def _execute_language_model_processing(self, state: ChatConversationState) -> Dict[str, List[BaseMessage]]:\n",
    "        \"\"\" Execute the language model processing step\"\"\"\n",
    "        try:\n",
    "            logger.debug(\"üß† Processing messages through language model...\")\n",
    "            res = await self.enhanced_llm.ainvoke(state['messages'])\n",
    "            logger.debug(f\"üîç Model response: {res}\")\n",
    "            return {'messages': res}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå LLM processing failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def _route_to_appropriate_node(self, state: ChatConversationState) -> str:\n",
    "        \"\"\" Determine the next node in the workflow\"\"\"\n",
    "        try:\n",
    "            last_msg = state['messages'][-1]\n",
    "\n",
    "            # check if last message contains a tool call\n",
    "            has_tool_calls = (\n",
    "                hasattr(last_msg, 'tool_calls') and\n",
    "                len(last_msg.tool_calls) > 0\n",
    "            )\n",
    "            if has_tool_calls:\n",
    "                logger.info(f\"üîß Tool execution required: {len(last_msg.tool_calls)} calls\")\n",
    "                return 'tool_execution_node'\n",
    "            else:\n",
    "                logger.debug(\"‚úÖ No tool calls detected, ending workflow.\")\n",
    "                return END\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Node routing failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def _execute_tool_operations(self, state: ChatConversationState) -> Dict[str, List[ToolMessage]]:\n",
    "        \"\"\" Execute any required tool operations\"\"\"\n",
    "        try:\n",
    "            logger.info(\"üîß Executing tool operations...\")\n",
    "            tool_calls = state['messages'][-1].tool_calls\n",
    "            executed_tools = []\n",
    "\n",
    "            for t in tool_calls:\n",
    "                logger.debug(f\"üîç Executing tool: {t['name']} with input: {t['args']}\")\n",
    "                tool_result = await self._process_individual_tool_call(t)\n",
    "                executed_tools.append(tool_result)\n",
    "            \n",
    "            logger.debug(f\"‚úÖ Executed {len(executed_tools)} & its results: {executed_tools}\")\n",
    "            return {'messages': executed_tools}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Tool execution failed: {e}\")\n",
    "            return {'messages': []}\n",
    "        \n",
    "    async def _process_individual_tool_call(self, tool_call: Dict[str, Any]) -> ToolMessage:\n",
    "        \"\"\" Process an individual tool call\"\"\"\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call.get('args', {})\n",
    "        tool_identifier = tool_call['id']\n",
    "\n",
    "        logger.debug(f\"üîç Processing tool call id: {tool_identifier} || name: {tool_name} || with args: {tool_args}\")\n",
    "        try:\n",
    "            if tool_name == self.search_tool.name:\n",
    "                search_results = await self.search_tool.ainvoke(tool_args)\n",
    "                tool_msg = ToolMessage(\n",
    "                    content=str(search_results),\n",
    "                    tool_call_id=tool_identifier,\n",
    "                    name=tool_name\n",
    "                )\n",
    "                logger.info(f\"üîç Search completed for query: {tool_args.get('query', 'unknown')}\")\n",
    "                return tool_msg \n",
    "            else:\n",
    "                logger.warning(f\"‚ö†Ô∏è Unknown tool requested: {tool_name}\")\n",
    "                return ToolMessage(\n",
    "                    content=f\"Unknown tool: {tool_name}\",\n",
    "                    tool_call_id=tool_identifier,\n",
    "                    name=tool_name\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Tool {tool_name} execution failed: {str(e)}\")\n",
    "            return ToolMessage(\n",
    "                content=f\"Tool execution failed: {str(e)}\",\n",
    "                tool_call_id=tool_identifier,\n",
    "                name=tool_name\n",
    "            )\n",
    "        \n",
    "    def visualize_conversation_workflow(self) -> None:\n",
    "        \"\"\" Visualize the conversation workflow graph\"\"\"\n",
    "        try:\n",
    "            graph_obj_getter = getattr(self.app, 'get_graph', None)\n",
    "            graph_obj = graph_obj_getter() if callable(graph_obj_getter) else self._graph\n",
    "\n",
    "            # 2. Mermaid source ---------------------------------------------------\n",
    "            if hasattr(graph_obj, 'draw_mermaid'):\n",
    "                try:\n",
    "                    mermaid_src = graph_obj.draw_mermaid()\n",
    "                    print(mermaid_src)\n",
    "                    logger.info(\"üß™ Mermaid diagram (text) printed.\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(\"‚ö†Ô∏è Mermaid render not available: %s\", e)\n",
    "\n",
    "            # 3. ASCII fallback ---------------------------------------------------\n",
    "            if hasattr(graph_obj, 'draw_ascii'):\n",
    "                try:\n",
    "                    ascii_map = graph_obj.draw_ascii()\n",
    "                    print(ascii_map)\n",
    "                    logger.info(\"üìÑ ASCII graph printed.\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    logger.debug(\"‚ö†Ô∏è ASCII render not available: %s\", e)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ùå Graph visualization failed: {e}\")\n",
    "\n",
    "    async def process_user_message(\n",
    "            self,\n",
    "            user_message: str,\n",
    "            conversation_id: Optional[Union[str, int]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Process a user message through the complete conversation workflow.\n",
    "        \n",
    "        Args:\n",
    "            user_message: The message from the user to process\n",
    "            conversation_id: Optional conversation identifier for memory continuity\n",
    "        \"\"\"\n",
    "        if not user_message or not user_message.strip():\n",
    "            logger.error(\"‚ö†Ô∏è Empty user message provided, skipping processing.\")\n",
    "            raise ValueError(\"User message cannot be empty.\")\n",
    "        \n",
    "        # generate a conversation id if not provided\n",
    "        if conversation_id is None:\n",
    "            conversation_id = str(uuid4())\n",
    "            logger.debug(f\"üÜï Generated new conversation ID: {conversation_id}\")\n",
    "        \n",
    "        conversation_config = {\n",
    "            'configurable': {\n",
    "                'thread_id': conversation_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        print(f\"\\nüë§ User: {user_message}\")\n",
    "        logger.info(f\"üë§ User (id: {conversation_id}): {user_message}\")\n",
    "        print(\"ü§ñ Assistant: \", end=\"\", flush=True)\n",
    "\n",
    "        assistant_response = \"\"\n",
    "        search_performed = False\n",
    "\n",
    "        try:\n",
    "            async for e in self.app.astream(\n",
    "                {'messages': [HumanMessage(content=user_message)]},\n",
    "                config=conversation_config,\n",
    "                version='v2'\n",
    "            ):\n",
    "                event_type = e.get('event', '')\n",
    "                if event_type == 'on_chat_model_stream':\n",
    "                    chunk = e.get('data', {}).get('chunk')\n",
    "                    if chunk and hasattr(chunk, 'content'):\n",
    "                        chunk_content = getattr(chunk, 'content', '')\n",
    "                        if chunk_content:\n",
    "                            print(chunk.content, end=\"\", flush=True)\n",
    "                            logger.debug(f\"üí¨ Streaming: {chunk.content}\")\n",
    "                            assistant_response += chunk.content\n",
    "                elif event_type == 'on_tool_start':\n",
    "                    tool_name = e.get('data', {}).get('tool_name', '')\n",
    "                    if tool_name == \"tavily_search_results_json\":\n",
    "                        if not search_performed:\n",
    "                            print(\"\\nüîç Searching the web...\", end=\"\", flush=True)\n",
    "                            logger.debug(f\"üîß Tool starting: {tool_name}\")\n",
    "                            search_performed = True\n",
    "                elif event_type == \"on_tool_end\":\n",
    "                    tool_name = e.get(\"name\", \"\")\n",
    "                    if tool_name == \"tavily_search_results_json\":\n",
    "                        print(\"\\nü§ñ Assistant: \", end=\"\", flush=True)\n",
    "                        logger.debug(f\"‚úÖ Tool completed: {tool_name}\")\n",
    "                print()  \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Message processing failed: {e}\")\n",
    "            print(f\"\\n‚ùå An error occurred: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa269843",
   "metadata": {},
   "source": [
    "## Run demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a852db",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_chat_assistant():\n",
    "    \"\"\"\n",
    "    Demonstration function showing how to use the enhanced chat assistant.\n",
    "    \n",
    "    This function provides examples of:\n",
    "    - Basic initialization\n",
    "    - Interactive chat display\n",
    "    - Message processing with real-time streaming\n",
    "    - Error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üéØ Starting Chat Assistant Demonstration...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Initialize the chat assistant\n",
    "        chat_assistant = ChatAssistantNotebook(\n",
    "            model_name=\"gemini-2.5-flash\",\n",
    "            max_search_results=2,\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Chat Assistant initialized successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Process example messages\n",
    "        test_messages = [\n",
    "            \"Hi, my name is Jiten\",\n",
    "            \"When is the next SpaceX launch?\",\n",
    "            \"Whats my name?\"\n",
    "        ]\n",
    "        \n",
    "        for message in test_messages:\n",
    "            await chat_assistant.process_user_message(message)\n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        print(\"‚úÖ Demonstration completed successfully\")\n",
    "        \n",
    "    except Exception as demo_error:\n",
    "        print(f\"‚ùå Demonstration failed: {str(demo_error)}\")\n",
    "        logger.error(f\"‚ùå Demonstration failed: {str(demo_error)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b2798eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Starting Chat Assistant Demonstration...\n",
      "============================================================\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | üöÄ Initializing Enhanced Chat Assistant...\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | ‚úÖ Language model 'gemini-2.5-flash' initialized.\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | ‚úÖ Search tool initialized and enhances llm capabilities.\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | ‚úÖ Memory manager initialized.\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | ‚úÖ Conversation workflow graph created and compiled.\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | ‚úÖ Chat Assistant initialized successfully.\n",
      "‚úÖ Chat Assistant initialized successfully!\n",
      "============================================================\n",
      "2025-09-06 14:20:20 | DEBUG    | __main__ | üÜï Generated new conversation ID: fa115c37-f93b-4a6b-b5e1-f4e750ec488e\n",
      "\n",
      "üë§ User: Hi, my name is Jiten\n",
      "2025-09-06 14:20:20 | INFO     | __main__ | üë§ User (id: fa115c37-f93b-4a6b-b5e1-f4e750ec488e): Hi, my name is Jiten\n",
      "ü§ñ Assistant: 2025-09-06 14:20:20 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:20:22 | DEBUG    | __main__ | üîç Model response: content='Hello Jiten, nice to meet you. How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--2b68f850-c31e-4a6b-8156-6b7b84a1668d-0' usage_metadata={'input_tokens': 81, 'output_tokens': 16, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}}\n",
      "2025-09-06 14:20:22 | DEBUG    | __main__ | ‚úÖ No tool calls detected, ending workflow.\n",
      "\n",
      "------------------------------------------------------------\n",
      "2025-09-06 14:20:22 | DEBUG    | __main__ | üÜï Generated new conversation ID: b06cdb03-12cb-40ae-8381-a7e713e9b174\n",
      "\n",
      "üë§ User: When is the next SpaceX launch?\n",
      "2025-09-06 14:20:22 | INFO     | __main__ | üë§ User (id: b06cdb03-12cb-40ae-8381-a7e713e9b174): When is the next SpaceX launch?\n",
      "ü§ñ Assistant: 2025-09-06 14:20:22 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:20:23 | DEBUG    | __main__ | üîç Model response: content='' additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"next SpaceX launch\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--a1e7bb0c-75bb-4cdb-889b-a1a83907ed83-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'next SpaceX launch'}, 'id': 'e9c65f59-b73d-463e-8a6b-c107d92867f5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 81, 'output_tokens': 83, 'total_tokens': 164, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 60}}\n",
      "2025-09-06 14:20:23 | INFO     | __main__ | üîß Tool execution required: 1 calls\n",
      "\n",
      "2025-09-06 14:20:23 | INFO     | __main__ | üîß Executing tool operations...\n",
      "2025-09-06 14:20:23 | DEBUG    | __main__ | üîç Executing tool: tavily_search_results_json with input: {'query': 'next SpaceX launch'}\n",
      "2025-09-06 14:20:23 | DEBUG    | __main__ | üîç Processing tool call id: e9c65f59-b73d-463e-8a6b-c107d92867f5 || name: tavily_search_results_json || with args: {'query': 'next SpaceX launch'}\n",
      "2025-09-06 14:20:26 | INFO     | __main__ | üîç Search completed for query: next SpaceX launch\n",
      "2025-09-06 14:20:26 | DEBUG    | __main__ | ‚úÖ Executed 1 & its results: [ToolMessage(content='[{\\'title\\': \\'SpaceX morning rocket launch in Florida: What time is liftoff ...\\', \\'url\\': \\'https://www.floridatoday.com/story/news/2025/09/04/spacex-launch-florida-what-time-canaveral-nasa/85880208007/\\', \\'content\\': \"Mission:A SpaceX Falcon 9 rocket will launch the next batch of Starlink internet satellites into low-Earth orbit.\\\\n Launch window: 6:56 a.m. to 10:56 a.m. ET Friday, Sept. 5, 2025\\\\n Trajectory: Northeast\\\\n Launch location:Launch pad 39A at NASA\\'s Kennedy Space Center in Florida\\\\n Sonic booms for the Space Coast of Florida (Titusville, Merritt Island, Cocoa Beach, Melbourne area): No [...] For questions or comments, email FLORIDA TODAY Space Reporter Rick Neale at rneale@floridatoday.com or Space Reporter Brooke Edwards at bedwards@floridatoday.com.\\\\n\\\\n## When is the next rocket launch in Florida? Friday, Sept. 5: SpaceX Starlink 10-57\", \\'score\\': 0.8449346}, {\\'title\\': \\'SpaceX Launch Manifest - Next Spaceflight\\', \\'url\\': \\'https://nextspaceflight.com/launches/agency/upcoming/1/\\', \\'content\\': \\'SpaceX Launch Manifest\\\\n\\\\nNEXT SPACEFLIGHTLaunchesEventsStarshipRocketsReuseLocations\\\\n\\\\nNEXT SPACEFLIGHTImage 1 LaunchesImage 2 EventsImage 3 StarshipImage 4 RocketsImage 5 ReuseImage 6 Locations\\\\n\\\\n### SpaceX Manifest\\\\n\\\\nUpcomingPast\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Starlink Group 10-14\\\\n\\\\n JRTI \\\\n\\\\nSun Aug 31, 2025 11:20 UTC\\\\n\\\\nSLC-40, Cape Canaveral SFS, Florida, USA \\\\n\\\\nDetailsWatch\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Starlink Group 17-8\\\\n\\\\n OCISLY \\\\n\\\\nWed Sep 03, 2025 02:33 UTC [...] DetailsWatch\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Nusantara Lima\\\\n\\\\n NET Sep 8, 2025 \\\\n\\\\nSLC-40, Cape Canaveral SFS, Florida, USA \\\\n\\\\nDetails\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Tranche 1 Transport Layer B\\\\n\\\\n NET Sep 10, 2025 \\\\n\\\\nSLC-4E, Vandenberg SFB, California, USA \\\\n\\\\nDetails\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | CRS NG-23\\\\n\\\\n LZ-2 \\\\n\\\\nMon Sep 15, 2025 21:49 UTC\\\\n\\\\nSLC-40, Cape Canaveral SFS, Florida, USA \\\\n\\\\nDetailsWatch\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | IMAP & Others\\\\n\\\\n NET Sep 23, 2025 [...] SLC-4E, Vandenberg SFB, California, USA \\\\n\\\\nDetailsWatch\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Starlink Group 10-22\\\\n\\\\n ASOG \\\\n\\\\nWed Sep 03, 2025 11:06 UTC\\\\n\\\\nSLC-40, Cape Canaveral SFS, Florida, USA \\\\n\\\\nDetailsWatch\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Starlink Group 10-57\\\\n\\\\n JRTI \\\\n\\\\nThu Sep 04, 2025 11:18 UTC\\\\n\\\\nLC-39A, Kennedy Space Center, Florida, USA \\\\n\\\\nDetailsWatch\\\\n\\\\n SpaceX \\\\n\\\\n##### Falcon 9 Block 5 | Starlink Group 17-9\\\\n\\\\n OCISLY \\\\n\\\\nSat Sep 06, 2025 15:42 UTC\\\\n\\\\nSLC-4E, Vandenberg SFB, California, USA\\', \\'score\\': 0.8215175}]', name='tavily_search_results_json', tool_call_id='e9c65f59-b73d-463e-8a6b-c107d92867f5')]\n",
      "\n",
      "2025-09-06 14:20:26 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:20:30 | DEBUG    | __main__ | üîç Model response: content=\"The next SpaceX launch is a Falcon 9 rocket carrying Starlink internet satellites, scheduled for Friday, September 5, 2025. The launch window is between 6:56 a.m. and 10:56 a.m. ET from Launch pad 39A at NASA's Kennedy Space Center in Florida.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--9fa84d95-b04a-4813-ae3e-576ac0fd26a5-0' usage_metadata={'input_tokens': 1151, 'output_tokens': 499, 'total_tokens': 1650, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 426}}\n",
      "2025-09-06 14:20:30 | DEBUG    | __main__ | ‚úÖ No tool calls detected, ending workflow.\n",
      "\n",
      "------------------------------------------------------------\n",
      "2025-09-06 14:20:30 | DEBUG    | __main__ | üÜï Generated new conversation ID: 598cad70-0c57-4f97-aefc-557f5abe7528\n",
      "\n",
      "üë§ User: Whats my name?\n",
      "2025-09-06 14:20:30 | INFO     | __main__ | üë§ User (id: 598cad70-0c57-4f97-aefc-557f5abe7528): Whats my name?\n",
      "ü§ñ Assistant: 2025-09-06 14:20:30 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:20:31 | DEBUG    | __main__ | üîç Model response: content='I do not know your name. I am a large language model, trained by Google. I do not have access to any personal information about you.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--2da801dd-a8ba-4587-b20d-0d64ea0679c8-0' usage_metadata={'input_tokens': 78, 'output_tokens': 30, 'total_tokens': 108, 'input_token_details': {'cache_read': 0}}\n",
      "2025-09-06 14:20:31 | DEBUG    | __main__ | ‚úÖ No tool calls detected, ending workflow.\n",
      "\n",
      "------------------------------------------------------------\n",
      "‚úÖ Demonstration completed successfully\n"
     ]
    }
   ],
   "source": [
    "await demonstrate_chat_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d362aaf",
   "metadata": {},
   "source": [
    "## Run interactive chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f7c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def interactive_chat():\n",
    "    \"\"\"\n",
    "    Interactive chat function for manual testing with user input.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üöÄ Starting Interactive Chat Assistant...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Initialize the chat assistant\n",
    "        chat_assistant = ChatAssistantNotebook(\n",
    "            model_name=\"gemini-2.5-flash\",\n",
    "            max_search_results=4,\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Chat Assistant ready! Type 'quit' to exit.\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        conversation_id = uuid4()\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\nüë§ You: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "                    print(\"üëã Goodbye!\")\n",
    "                    break\n",
    "                \n",
    "                if not user_input:\n",
    "                    print(\"‚ö†Ô∏è Please enter a message.\")\n",
    "                    continue\n",
    "                \n",
    "                await chat_assistant.process_user_message(user_input, conversation_id)\n",
    "                print(\"-\" * 60)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nüëã Chat interrupted. Goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "                \n",
    "    except Exception as init_error:\n",
    "        print(f\"‚ùå Failed to initialize chat: {str(init_error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b05506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Interactive Chat Assistant...\n",
      "============================================================\n",
      "2025-09-06 14:24:52 | INFO     | __main__ | üöÄ Initializing Enhanced Chat Assistant...\n",
      "2025-09-06 14:24:52 | INFO     | __main__ | ‚úÖ Language model 'gemini-2.5-flash' initialized.\n",
      "2025-09-06 14:24:52 | INFO     | __main__ | ‚úÖ Search tool initialized and enhances llm capabilities.\n",
      "2025-09-06 14:24:52 | INFO     | __main__ | ‚úÖ Memory manager initialized.\n",
      "2025-09-06 14:24:52 | INFO     | __main__ | ‚úÖ Conversation workflow graph created and compiled.\n",
      "2025-09-06 14:24:52 | INFO     | __main__ | ‚úÖ Chat Assistant initialized successfully.\n",
      "‚úÖ Chat Assistant ready! Type 'quit' to exit.\n",
      "============================================================\n",
      "\n",
      "üë§ User: hi my name is jiten\n",
      "2025-09-06 14:25:00 | INFO     | __main__ | üë§ User (id: 285829db-1aaf-4470-85f6-902094fcfa66): hi my name is jiten\n",
      "ü§ñ Assistant: 2025-09-06 14:25:00 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:25:02 | DEBUG    | __main__ | üîç Model response: content='Hi Jiten, nice to meet you! How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--0a318889-e4c1-4b6c-adeb-0bd36d22f3a2-0' usage_metadata={'input_tokens': 80, 'output_tokens': 16, 'total_tokens': 96, 'input_token_details': {'cache_read': 0}}\n",
      "2025-09-06 14:25:02 | DEBUG    | __main__ | ‚úÖ No tool calls detected, ending workflow.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üë§ User: hows the weather in mumbai today?\n",
      "2025-09-06 14:25:24 | INFO     | __main__ | üë§ User (id: 285829db-1aaf-4470-85f6-902094fcfa66): hows the weather in mumbai today?\n",
      "ü§ñ Assistant: 2025-09-06 14:25:24 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:25:25 | DEBUG    | __main__ | üîç Model response: content='' additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather in Mumbai today\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--f37f069d-2ad3-4e9f-9c79-49cdccbcf981-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Mumbai today'}, 'id': '33c921b1-61be-4736-86fd-2da090a33f2b', 'type': 'tool_call'}] usage_metadata={'input_tokens': 106, 'output_tokens': 78, 'total_tokens': 184, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 54}}\n",
      "2025-09-06 14:25:25 | INFO     | __main__ | üîß Tool execution required: 1 calls\n",
      "\n",
      "2025-09-06 14:25:25 | INFO     | __main__ | üîß Executing tool operations...\n",
      "2025-09-06 14:25:25 | DEBUG    | __main__ | üîç Executing tool: tavily_search_results_json with input: {'query': 'weather in Mumbai today'}\n",
      "2025-09-06 14:25:25 | DEBUG    | __main__ | üîç Processing tool call id: 33c921b1-61be-4736-86fd-2da090a33f2b || name: tavily_search_results_json || with args: {'query': 'weather in Mumbai today'}\n",
      "2025-09-06 14:25:31 | INFO     | __main__ | üîç Search completed for query: weather in Mumbai today\n",
      "2025-09-06 14:25:31 | DEBUG    | __main__ | ‚úÖ Executed 1 & its results: [ToolMessage(content='[{\\'title\\': \\'Mumbai weather in September 2025 | India: How hot?\\', \\'url\\': \\'https://www.weather2travel.com/india/mumbai/september/\\', \\'content\\': \"weather2travel.com - travel deals for your holiday in the sun\\\\nClick to search\\\\n\\\\n# Mumbai weather in September 2025\\\\n\\\\nExpect  daytime maximum temperatures of 30¬∞C in Mumbai, India in September and high heat and humidity based on long-term weather averages. There are 6 hours of sunshine per day on average with 13 days with some rainfall and typically 347 mm of rainfall in the month. [...] 30¬∞C maximum daytime temperature in September in Mumbai\\\\n6 hours of sunshine per day (47% of daylight hours) in September in Mumbai\\\\n13 days with some rainfall in September in Mumbai\\\\n25¬∞C minimum night-time temperature in September in Mumbai\\\\n12 hours of daylight per day in September in Mumbai\\\\nHigh heat & humidity in September in Mumbai\\\\n347 mm monthly rainfall in September in Mumbai\\\\nUV (maximum) index 11+ (Extreme) in September in Mumbai\\\\n28¬∞C sea temperature in September in Mumbai [...] 9 must-see sights for first-time travellers to India\\\\n9 must-see sights for first-time travellers to India\\\\n6 misconceptions about New Delhi\\\\n6 misconceptions about New Delhi\\\\n9 reasons to visit Goa (which don\\'t involve beaches)\\\\n9 reasons to visit Goa (which don\\'t involve beaches)\\\\n\\\\n### How hot is it in Mumbai in September?\\\\n\\\\nDaytime temperatures usually reach 30¬∞C in Mumbai in September with high heat and humidity, falling to 25¬∞C at night.\\\\n\\\\n### How sunny is it in Mumbai in September?\", \\'score\\': 0.8430832}, {\\'title\\': \\'Mumbai weather in September 2025 - Weather25.com\\', \\'url\\': \\'https://www.weather25.com/asia/india/maharashtra/mumbai?page=month&month=September\\', \\'content\\': \\'The weather in Mumbai in September is very hot. The average temperatures are between 26¬∞C and 30¬∞C, drinking water regularly is advisable.\\\\n\\\\nYou can expect rain for roughly half of the month of September in Mumbai. We‚Äôre expecting roughly 8 to 15 days of rain, so your rubber boots and umbrella are going to see plenty of use this month if you‚Äôre keen on staying dry.\\\\n\\\\nOur weather forecast can give you a great sense of what weather to expect in Mumbai in September 2025. [...] weather25.com\\\\nSearch\\\\nweather in India\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in India\\\\n\\\\n# Mumbai weather in September 2025\\\\n\\\\nLight rain shower\\\\nLight rain shower\\\\nLight rain shower\\\\nPatchy rain possible\\\\nPatchy rain possible\\\\nPatchy rain possible\\\\nCloudy\\\\nPatchy rain possible\\\\nPatchy rain possible\\\\nModerate or heavy rain shower\\\\nLight rain shower\\\\nLight rain shower\\\\nLight rain shower\\\\nLight rain shower\\\\n\\\\n## The average weather in Mumbai in September [...] | June | 31¬∞ / 28¬∞ | 17 | 13 | 0 | 673 mm | Ok | Mumbai in June |\\\\n| July | 29¬∞ / 27¬∞ | 26 | 5 | 0 | 1318 mm | Ok | Mumbai in July |\\\\n| August | 29¬∞ / 26¬∞ | 21 | 10 | 0 | 779 mm | Ok | Mumbai in August |\\\\n| September | 30¬∞ / 26¬∞ | 14 | 16 | 0 | 408 mm | Ok | Mumbai in September |\\\\n| October | 33¬∞ / 27¬∞ | 4 | 27 | 0 | 106 mm | Good | Mumbai in October |\\\\n| November | 34¬∞ / 26¬∞ | 2 | 28 | 0 | 44 mm | Ok | Mumbai in November |\\\\n| December | 32¬∞ / 24¬∞ | 0 | 31 | 0 | 8 mm | Good | Mumbai in December |\\', \\'score\\': 0.82694983}, {\\'title\\': \\'Mumbai, Maharashtra, India Monthly Weather\\', \\'url\\': \\'https://www.accuweather.com/en/in/mumbai/204842/june-weather/204842\\', \\'content\\': \\'# Mumbai, Maharashtra\\\\n\\\\nMumbai\\\\n\\\\nMaharashtra\\\\n\\\\n## Around the Globe\\\\n\\\\nAround the Globe\\\\n\\\\n### Hurricane Tracker\\\\n\\\\n### Severe Weather\\\\n\\\\n### Radar & Maps\\\\n\\\\n### News & Features\\\\n\\\\n### Astronomy\\\\n\\\\n### Business\\\\n\\\\n### Climate\\\\n\\\\n### Health\\\\n\\\\n### Recreation\\\\n\\\\n### Sports\\\\n\\\\n### Travel\\\\n\\\\n### Warnings\\\\n\\\\n### Data Suite\\\\n\\\\n### Forensics\\\\n\\\\n### Advertising\\\\n\\\\n### Superior Accuracy‚Ñ¢\\\\n\\\\n### Video\\\\n\\\\n## Monthly\\\\n\\\\n## June\\\\n\\\\n## 2025\\\\n\\\\n## Daily\\\\n\\\\n## Temperature Graph\\\\n\\\\n## Further Ahead\\\\n\\\\nFurther Ahead\\\\n\\\\n### July 2025\\\\n\\\\n### August 2025 [...] ### September 2025\\\\n\\\\n## Around the Globe\\\\n\\\\nAround the Globe\\\\n\\\\n### Hurricane Tracker\\\\n\\\\n### Severe Weather\\\\n\\\\n### Radar & Maps\\\\n\\\\n### News\\\\n\\\\n### Video\\\\n\\\\nTop Stories\\\\n\\\\nHurricane\\\\n\\\\nAtlantic tropical rainstorm may reach Caribbean as a hurricane\\\\n\\\\n1 hour ago\\\\n\\\\nWeather News\\\\n\\\\nTexas to enact sweeping camp safety law to protect kids\\\\n\\\\n18 hours ago\\\\n\\\\nWeather Forecasts\\\\n\\\\nOctober-like conditions to spread across much of central, eastern U.S.\\\\n\\\\n1 hour ago\\\\n\\\\nAstronomy [...] 85% of world population may see total lunar eclipse on Sunday\\\\n\\\\n19 hours ago\\\\n\\\\nSevere Weather\\\\n\\\\nSevere storms to spring to life in eastern US\\\\n\\\\n10 hours ago\\\\n\\\\nFeatured Stories\\\\n\\\\nWeather News\\\\n\\\\nFAA investigating plane that went off end of runway after landing at C...\\\\n\\\\n1 day ago\\\\n\\\\nWinter Weather\\\\n\\\\nCan woolly bear caterpillars predict winter weather?\\\\n\\\\n16 hours ago\\\\n\\\\nRecreation\\\\n\\\\nPowerball win or a lightning strike: Which has better odds?\\\\n\\\\n2 days ago\\\\n\\\\nWeather News\\', \\'score\\': 0.4767995}, {\\'title\\': \\'Mumbai, Maharashtra, India Monthly Weather - AccuWeather\\', \\'url\\': \\'https://www.accuweather.com/en/in/mumbai/204842/september-weather/204842\\', \\'content\\': \\'Get the monthly weather forecast for Mumbai, Maharashtra, India, including daily high/low, historical averages, to help you plan ahead.\\', \\'score\\': 0.15452935}]', name='tavily_search_results_json', tool_call_id='33c921b1-61be-4736-86fd-2da090a33f2b')]\n",
      "\n",
      "2025-09-06 14:25:31 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:25:33 | DEBUG    | __main__ | üîç Model response: content=\"I couldn't find the weather for today in Mumbai, but I found the forecast for September 2025. It's expected to be very hot with average temperatures between 26¬∞C and 30¬∞C, and there's a high chance of rain for about half of the month.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--c14244dd-0809-44e1-abb1-97db609595b2-0' usage_metadata={'input_tokens': 1871, 'output_tokens': 231, 'total_tokens': 2102, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 166}}\n",
      "2025-09-06 14:25:33 | DEBUG    | __main__ | ‚úÖ No tool calls detected, ending workflow.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üë§ User: do you remember my name?\n",
      "2025-09-06 14:25:55 | INFO     | __main__ | üë§ User (id: 285829db-1aaf-4470-85f6-902094fcfa66): do you remember my name?\n",
      "ü§ñ Assistant: 2025-09-06 14:25:55 | DEBUG    | __main__ | üß† Processing messages through language model...\n",
      "2025-09-06 14:25:56 | DEBUG    | __main__ | üîç Model response: content='Yes, your name is Jiten.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--03241744-a363-477d-971d-4dd468b3d8e3-0' usage_metadata={'input_tokens': 1944, 'output_tokens': 8, 'total_tokens': 1952, 'input_token_details': {'cache_read': 0}}\n",
      "2025-09-06 14:25:56 | DEBUG    | __main__ | ‚úÖ No tool calls detected, ending workflow.\n",
      "\n",
      "------------------------------------------------------------\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "await interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181a1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InfoBuddy.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
